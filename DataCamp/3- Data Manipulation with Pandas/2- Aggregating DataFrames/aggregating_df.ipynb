{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean and median\n",
    "Summary statistics are exactly what they sound like - they summarize many numbers in one statistic. For example, mean, median, minimum, maximum, and standard deviation are summary statistics. Calculating summary statistics allows you to get a better sense of your data, even if there's a lot of it.\n",
    "\n",
    "**sales** is available and **pandas** is loaded as **pd**.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Explore your new DataFrame first by printing the first few rows of the **sales** DataFrame.\n",
    "- Print information about the columns in **sales**.\n",
    "- Print the mean of the **weekly_sales** column.\n",
    "- Print the median of the **weekly_sales** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store type  department        date  weekly_sales  is_holiday  \\\n",
      "0      1    A           1  2010-02-05      24924.50       False   \n",
      "1      1    A           1  2010-03-05      21827.90       False   \n",
      "2      1    A           1  2010-04-02      57258.43       False   \n",
      "3      1    A           1  2010-05-07      17413.94       False   \n",
      "4      1    A           1  2010-06-04      17558.09       False   \n",
      "\n",
      "   temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0       5.727778              0.679451         8.106  \n",
      "1       8.055556              0.693452         8.106  \n",
      "2      16.816667              0.718284         7.808  \n",
      "3      22.527778              0.748928         7.808  \n",
      "4      27.050000              0.714586         7.808  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10774 entries, 0 to 10773\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   store                 10774 non-null  int64  \n",
      " 1   type                  10774 non-null  object \n",
      " 2   department            10774 non-null  int64  \n",
      " 3   date                  10774 non-null  object \n",
      " 4   weekly_sales          10774 non-null  float64\n",
      " 5   is_holiday            10774 non-null  bool   \n",
      " 6   temperature_c         10774 non-null  float64\n",
      " 7   fuel_price_usd_per_l  10774 non-null  float64\n",
      " 8   unemployment          10774 non-null  float64\n",
      "dtypes: bool(1), float64(4), int64(2), object(2)\n",
      "memory usage: 768.1+ KB\n",
      "None\n",
      "23843.950148505668\n",
      "12049.064999999999\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sales = pd.read_csv('../sales_subset.csv',index_col=0)\n",
    "\n",
    "print(sales.head())\n",
    "\n",
    "print(sales.info())\n",
    "\n",
    "print(sales[\"weekly_sales\"].mean())\n",
    "\n",
    "print(sales.weekly_sales.median()) #if column names is letter and number can use .(dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing dates\n",
    "Summary statistics can also be calculated on date columns that have values with the data type **datetime64**. Some summary statistics — like mean — don't make a ton of sense on dates, but others are super helpful, for example, minimum and maximum, which allow you to see what time range your data covers.\n",
    "\n",
    "**sales** is available and **pandas** is loaded as **pd**.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Print the maximum of the **date** column.\n",
    "- Print the minimum of the **date** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-10-26\n",
      "2010-02-05\n"
     ]
    }
   ],
   "source": [
    "print(sales.date.max())\n",
    "\n",
    "print(sales.date.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient summaries\n",
    "While pandas and NumPy have tons of functions, sometimes, you may need a different function to summarize your data.\n",
    "\n",
    "The **.agg()** method allows you to apply your own custom functions to a DataFrame, as well as apply functions to more than one column of a DataFrame at once, making your aggregations super-efficient. For example,\n",
    "\n",
    "***df['column'].agg(function)***\n",
    "\n",
    "In the custom function for this exercise, \"IQR\" is short for inter-quartile range, which is the 75th percentile minus the 25th percentile. It's an alternative to standard deviation that is helpful if your data contains outliers.\n",
    "\n",
    "**sales** is available and **pandas** is loaded as **pd**.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Use the custom **iqr** function defined for you along with **.agg()** to print the IQR of the **temperature_c** column of **sales**.\n",
    "- Update the column selection to use the custom **iqr** function with **.agg()** to print the IQR of **temperature_c**, **fuel_price_usd_per_l**, and **unemployment**, in that order.\n",
    "- Update the aggregation functions called by **.agg()**: include **iqr** and **np.median** in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        temperature_c  fuel_price_usd_per_l  unemployment\n",
      "iqr         16.583333              0.073176         0.565\n",
      "median      16.966667              0.743381         8.099\n"
     ]
    }
   ],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr, np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative statistics\n",
    "Cumulative statistics can also be helpful in tracking summary statistics over time. In this exercise, you'll calculate the cumulative sum and cumulative max of a department's weekly sales, which will allow you to identify what the total sales were so far as well as what the highest weekly sales were so far.\n",
    "\n",
    "A DataFrame called **sales_1_1** has been created for you, which contains the sales data for department 1 of store 1. **pandas** is loaded as **pd**.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Sort the rows of **sales_1_1** by the date column in ascending order.\n",
    "- Get the cumulative sum of **weekly_sales** and add it as a new column of **sales_1_1** called **cum_weekly_sales**.\n",
    "- Get the cumulative maximum of **weekly_sales**, and add it as a column called **cum_max_sales**.\n",
    "- Print the **date**, **weekly_sales**, **cum_weekly_sales**, and **cum_max_sales** columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  weekly_sales  cum_weekly_sales  cum_max_sales\n",
      "0   2010-02-05      24924.50          24924.50       24924.50\n",
      "1   2010-03-05      21827.90          46752.40       24924.50\n",
      "2   2010-04-02      57258.43         104010.83       57258.43\n",
      "3   2010-05-07      17413.94         121424.77       57258.43\n",
      "4   2010-06-04      17558.09         138982.86       57258.43\n",
      "5   2010-07-02      16333.14         155316.00       57258.43\n",
      "6   2010-08-06      17508.41         172824.41       57258.43\n",
      "7   2010-09-03      16241.78         189066.19       57258.43\n",
      "8   2010-10-01      20094.19         209160.38       57258.43\n",
      "9   2010-11-05      34238.88         243399.26       57258.43\n",
      "10  2010-12-03      22517.56         265916.82       57258.43\n",
      "11  2011-01-07      15984.24         281901.06       57258.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman\\AppData\\Local\\Temp/ipykernel_21004/2583384022.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\n",
      "C:\\Users\\Aman\\AppData\\Local\\Temp/ipykernel_21004/2583384022.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\n"
     ]
    }
   ],
   "source": [
    "sales_1_1 = sales[(sales[\"store\"] == 1) & (sales[\"department\"] == 1)]\n",
    "\n",
    "sales_1_1.sort_values('date')\n",
    "\n",
    "\n",
    "sales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\n",
    "\n",
    "sales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\n",
    "\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c49298971bf539fe56860cf72510440f9c691c8b4f7aa806b89e675cbf902fa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
