{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your first inner join\n",
    "You have been tasked with figuring out what the most popular types of fuel used in Chicago taxis are. To complete the analysis, you need to merge the taxi_owners and taxi_veh tables together on the vid column. You can then use the merged table along with the **.value_counts()** method to find the most common **fuel_type**.\n",
    "\n",
    "Since you'll be working with pandas throughout the course, the package will be preloaded for you as pd in each exercise in this course. Also the **taxi_owners** and **taxi_veh** DataFrames are loaded for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Merge taxi_owners with **taxi_veh** on the column vid, and save the result to **taxi_own_veh**.\n",
    "\n",
    "- Set the left and right table suffixes for overlapping columns of the merge to **_own** and **_veh**, respectively.\n",
    "\n",
    "- Select the **fuel_type** column from **taxi_own_veh** and print the **value_counts()** to find the most popular **fuel_types** used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "taxi_owners = pd.read_pickle('taxi_owners.p')\n",
    "taxi_veh = pd.read_pickle('taxi_vehicles.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYBRID                    2792\n",
      "GASOLINE                   611\n",
      "FLEX FUEL                   89\n",
      "COMPRESSED NATURAL GAS      27\n",
      "Name: fuel_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "taxi_own_veh = taxi_owners.merge(taxi_veh, on=\"vid\", suffixes=('_own', '_veh'))\n",
    "\n",
    "print(taxi_own_veh['fuel_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner joins and number of rows returned\n",
    "All of the merges you have studied to this point are called inner joins. It is necessary to understand that inner joins only return the rows with matching values in both tables. You will explore this further by reviewing the merge between the wards and census tables, then comparing it to merges of copies of these tables that are slightly altered, named **wards_altered**, and **census_altered**. The first row of the **wards** column has been changed in the altered tables. You will examine how this affects the merge between them. The tables have been loaded for you.\n",
    "\n",
    "For this exercise, it is important to know that the **wards** and **census** tables start with 50 rows.\n",
    "\n",
    "### Instructions\n",
    "- Merge wards and census on the **ward** column and save the result to **wards_census**.\n",
    "\n",
    "- Merge the **wards_altered** and census tables on the **ward** column, and notice the difference in returned rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ward        object\n",
      "pop_2000     int64\n",
      "pop_2010     int64\n",
      "change      object\n",
      "address     object\n",
      "zip         object\n",
      "dtype: object\n",
      "ward        object\n",
      "alderman    object\n",
      "address     object\n",
      "zip         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "wards = pd.read_pickle('ward.p')\n",
    "census = pd.read_pickle('census.p')\n",
    "wards_altered = pd.read_csv('wards_altered.csv')\n",
    "wards_altered[\"ward\"] = wards_altered[\"ward\"].astype('object')\n",
    "wards_altered[\"zip\"] = wards_altered[\"zip\"].astype('object')\n",
    "print(census.dtypes)\n",
    "print(wards_altered.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 9)\n"
     ]
    }
   ],
   "source": [
    "wards_census = wards.merge(census, on='ward')\n",
    "print(wards_census.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ward\n",
      "0   61\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "wards_altered_census table shape: (0, 9)\n"
     ]
    }
   ],
   "source": [
    "# Print the first few rows of the wards_altered table to view the change \n",
    "print(wards_altered[['ward']].head())\n",
    "\n",
    "# Merge the wards_altered and census tables on the ward column\n",
    "wards_altered_census = wards_altered.merge(census, on='ward')\n",
    "\n",
    "# Print the shape of wards_altered_census\n",
    "print('wards_altered_census table shape:', wards_altered_census.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-to-many merge\n",
    "A business may have one or multiple owners. In this exercise, you will continue to gain experience with one-to-many merges by merging a table of business owners, called **biz_owners**, to the **licenses** table. Recall from the video lesson, with a one-to-many relationship, a row in the left table may be repeated if it is related to multiple rows in the right table. In this lesson, you will explore this further by finding out what is the most common business owner title. (i.e., secretary, CEO, or vice president)\n",
    "\n",
    "The **licenses** and **biz_owners** DataFrames are loaded for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Starting with the **licenses** table on the left, merge it to the **biz_owners** table on the column **account**, and save the results to a variable named **licenses_owners**.\n",
    "- Group **licenses_owners** by **title** and count the number of accounts for each title. Save the result as **counted_df**\n",
    "- Sort **counted_df** by the number of **accounts** in **descending** order, and save this as a variable named **sorted_df**.\n",
    "- Use the **.head()** method to print the first few rows of the **sorted_df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_owners = pd.read_pickle('business_owners.p')\n",
    "licenses = pd.read_pickle('licenses.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "ASST. SECRETARY       111\n",
      "BENEFICIARY             4\n",
      "CEO                   110\n",
      "DIRECTOR              146\n",
      "EXECUTIVE DIRECTOR     10\n",
      "Name: account, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "licenses_owners = licenses.merge(biz_owners, on=\"account\")\n",
    "\n",
    "counted_df = licenses_owners.groupby(\"title\")[\"account\"].count()\n",
    "\n",
    "sortred_df = counted_df.sort_values(ascending=False)\n",
    "\n",
    "print(counted_df.head())\n",
    "\n",
    "#is not a dataframe, looks like an array of\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 account\n",
      "title                   \n",
      "PRESIDENT           6259\n",
      "SECRETARY           5205\n",
      "SOLE PROPRIETOR     1658\n",
      "OTHER               1200\n",
      "VICE PRESIDENT       970\n"
     ]
    }
   ],
   "source": [
    "licenses_owners = licenses.merge(biz_owners, on=\"account\")\n",
    "\n",
    "counted_df = licenses_owners.groupby(\"title\").agg({'account':'count'})\n",
    "\n",
    "sorted_df = counted_df.sort_values(\"account\",ascending=False)\n",
    "\n",
    "print(sorted_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total riders in a month\n",
    "Your goal is to find the total number of rides provided to passengers passing through the Wilson station (station_name == 'Wilson') when riding Chicago's public transportation system on weekdays (day_type == 'Weekday') in July (month == 7). Luckily, Chicago provides this detailed data, but it is in three different tables. You will work on merging these tables together to answer the question. This data is different from the business related data you have seen so far, but all the information you need to answer the question is provided.\n",
    "\n",
    "The **cal**, **ridership**, and **stations** DataFrames have been loaded for you. The relationship between the tables can be seen in the diagram below.\n",
    "\n",
    "The **cal** table relates to **ridership** via **year, month, and day**. The **ridership** table relates to the **stations** table via **station_id**.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Merge the **ridership** and **cal** tables together, starting with the **ridership** table on the left and save the result to the variable **ridership_cal**. If you code takes too long to run, your merge conditions might be incorrect.\n",
    "- Extend the previous merge to three tables by also merging the **stations** table.\n",
    "- Create a variable called **filter_criteria** to select the appropriate rows from the merged table so that you can sum the **rides** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station_id  year  month  day  rides\n",
      "0      40010  2019      1    1    576\n",
      "1      40010  2019      1    2   1457\n",
      "2      40010  2019      1    3   1543\n",
      "3      40010  2019      1    4   1621\n",
      "4      40010  2019      1    5    719\n",
      "   year  month  day        day_type\n",
      "0  2019      1    1  Sunday/Holiday\n",
      "1  2019      1    2         Weekday\n",
      "2  2019      1    3         Weekday\n",
      "3  2019      1    4         Weekday\n",
      "4  2019      1    5        Saturday\n",
      "  station_id        station_name                 location\n",
      "0      40010  Austin-Forest Park  (41.870851, -87.776812)\n",
      "1      40020         Harlem-Lake  (41.886848, -87.803176)\n",
      "2      40030        Pulaski-Lake  (41.885412, -87.725404)\n",
      "3      40040        Quincy/Wells   (41.878723, -87.63374)\n",
      "4      40050               Davis   (42.04771, -87.683543)\n"
     ]
    }
   ],
   "source": [
    "stations = pd.read_pickle('stations.p')\n",
    "cal = pd.read_pickle('cta_calendar.p')\n",
    "ridership = pd.read_pickle('cta_ridership.p')\n",
    "\n",
    "print(ridership.head())\n",
    "print(cal.head())\n",
    "print(stations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140005\n"
     ]
    }
   ],
   "source": [
    "# Merge the ridership and cal tables\n",
    "ridership_cal = ridership.merge(cal, on=[\"year\",\"month\",\"day\"])\n",
    "\n",
    "ridership_cal_stations = ridership.merge(cal, on=[\"year\",\"month\",\"day\"])\\\n",
    "    .merge(stations, on='station_id')\n",
    "\n",
    "filter_criteria = ((ridership_cal_stations['month'] == 7) & \\\n",
    "    (ridership_cal_stations[\"day_type\"] == \"Weekday\") & \\\n",
    "        (ridership_cal_stations[\"station_name\"] == \"Wilson\"))\n",
    "\n",
    "print(ridership_cal_stations.loc[filter_criteria,'rides'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three table merge\n",
    "To solidify the concept of a three DataFrame merge, practice another exercise. A reasonable extension of our review of Chicago business data would include looking at demographics information about the neighborhoods where the businesses are. A table with the median income by zip code has been provided to you. You will merge the licenses and wards tables with this new **income-by-zip-code** table called **zip_demo**.\n",
    "\n",
    "The **licenses**, **wards**, and **zip_demo** DataFrames have been loaded for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Starting with the **licenses** table, merge to it the **zip_demo** table on the **zip** column. Then merge the resulting table to the **wards** table on the **ward** column. Save result of the three merged tables to a variable named **licenses_zip_ward**.\n",
    "- Group the results of the three merged tables by the column **alderman** and find the median **income**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  account ward  aid                   business               address    zip\n",
      "0  307071    3  743       REGGIE'S BAR & GRILL       2105 S STATE ST  60616\n",
      "1      10   10  829                 HONEYBEERS   13200 S HOUSTON AVE  60633\n",
      "2   10002   14  775                CELINA DELI     5089 S ARCHER AVE  60632\n",
      "3   10005   12  NaN  KRAFT FOODS NORTH AMERICA        2005 W 43RD ST  60609\n",
      "4   10044   44  638  NEYBOUR'S TAVERN & GRILLE  3651 N SOUTHPORT AVE  60613      zip  income\n",
      "0  60630   70122\n",
      "1  60640   50488\n",
      "2  60622   87143\n",
      "3  60614  100116\n",
      "4  60608   41226   ward            alderman                          address    zip\n",
      "0    1  Proco \"Joe\" Moreno        2058 NORTH WESTERN AVENUE  60647\n",
      "1    2       Brian Hopkins       1400 NORTH  ASHLAND AVENUE  60622\n",
      "2    3          Pat Dowell          5046 SOUTH STATE STREET  60609\n",
      "3    4    William D. Burns  435 EAST 35TH STREET, 1ST FLOOR  60616\n",
      "4    5  Leslie A. Hairston            2325 EAST 71ST STREET  60649\n"
     ]
    }
   ],
   "source": [
    "zip_demo = pd.read_pickle('zip_demo.p')\n",
    "print(licenses.head(), zip_demo.head(), wards.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             income\n",
      "alderman                           \n",
      "Ameya Pawar                 66246.0\n",
      "Anthony A. Beale            38206.0\n",
      "Anthony V. Napolitano       82226.0\n",
      "Ariel E. Reyboras           41307.0\n",
      "Brendan Reilly             110215.0\n",
      "Brian Hopkins               87143.0\n",
      "Carlos Ramirez-Rosa         66246.0\n",
      "Carrie M. Austin            38206.0\n",
      "Chris Taliaferro            55566.0\n",
      "Daniel \"Danny\" Solis        41226.0\n",
      "David H. Moore              33304.0\n",
      "Deborah Mell                66246.0\n",
      "Debra L. Silverstein        50554.0\n",
      "Derrick G. Curtis           65770.0\n",
      "Edward M. Burke             42335.0\n",
      "Emma M. Mitts               36283.0\n",
      "George Cardenas             33959.0\n",
      "Gilbert Villegas            41307.0\n",
      "Gregory I. Mitchell         24941.0\n",
      "Harry Osterman              45442.0\n",
      "Howard B. Brookins, Jr.     33304.0\n",
      "James Cappleman             79565.0\n",
      "Jason C. Ervin              41226.0\n",
      "Joe Moore                   39163.0\n",
      "John S. Arena               70122.0\n",
      "Leslie A. Hairston          28024.0\n",
      "Margaret Laurino            70122.0\n",
      "Marty Quinn                 67045.0\n",
      "Matthew J. O'Shea           59488.0\n",
      "Michael R. Zalewski         42335.0\n",
      "Michael Scott, Jr.          31445.0\n",
      "Michelle A. Harris          32558.0\n",
      "Michelle Smith             100116.0\n",
      "Milagros \"Milly\" Santiago   41307.0\n",
      "Nicholas Sposato            62223.0\n",
      "Pat Dowell                  46340.0\n",
      "Patrick Daley Thompson      41226.0\n",
      "Patrick J. O'Connor         50554.0\n",
      "Proco \"Joe\" Moreno          87143.0\n",
      "Raymond A. Lopez            33959.0\n",
      "Ricardo Munoz               31445.0\n",
      "Roberto Maldonado           68223.0\n",
      "Roderick T. Sawyer          32558.0\n",
      "Scott Waguespack            68223.0\n",
      "Susan Sadlowski Garza       38417.0\n",
      "Tom Tunney                  88708.0\n",
      "Toni L. Foulkes             27573.0\n",
      "Walter Burnett, Jr.         87143.0\n",
      "William D. Burns           107811.0\n",
      "Willie B. Cochran           28024.0\n"
     ]
    }
   ],
   "source": [
    "licenses_zip_ward = licenses.merge(zip_demo, on=\"zip\")\\\n",
    "    .merge(wards, on=\"ward\")\n",
    "    \n",
    "print(licenses_zip_ward.groupby(\"alderman\").agg({\"income\":\"median\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-to-many merge with multiple tables\n",
    "In this exercise, assume that you are looking to start a business in the city of Chicago. Your perfect idea is to start a company that uses goats to mow the lawn for other businesses. However, you have to choose a location in the city to put your goat farm. You need a location with a great deal of space and relatively few businesses and people around to avoid complaints about the smell. You will need to merge three tables to help you choose your location. The **land_use** table has info on the percentage of vacant land by city ward. The census table has population by **ward**, and the **licenses** table lists businesses by ward.\n",
    "\n",
    "The **land_use**, **census**, and **licenses** tables have been loaded for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Merge **land_use** and **census** on the **ward** column. Merge the result of this with **licenses** on the **ward** column, using the suffix **_cen** for the left table and **_lic** for the right table. Save this to the variable **land_cen_lic**.\n",
    "- Group **land_cen_lic** by **ward**, **pop_2010** (the population in 2010), and **vacant**, then count the number of **accounts**. Save the results to **pop_vac_lic**.\n",
    "- Sort **pop_vac_lic** by **vacant**, **account**, and **pop_2010** in **descending**, **ascending**, and **ascending** order respectively. Save it as **sorted_pop_vac_lic**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ward  residential  commercial  industrial  vacant  other\n",
      "0    1           41           9           2       2     46\n",
      "1    2           31          11           6       2     50\n",
      "2    3           20           5           3      13     59\n",
      "3    4           22          13           0       7     58\n",
      "4    5           25           3           1       3     68\n",
      "  ward  pop_2000  pop_2010 change                                  address  \\\n",
      "0    1     52951     56149     6%              2765 WEST SAINT MARY STREET   \n",
      "1    2     54361     55805     3%                 WM WASTE MANAGEMENT 1500   \n",
      "2    3     40385     53039    31%                      17 EAST 38TH STREET   \n",
      "3    4     51953     54589     5%  31ST ST HARBOR BUILDING LAKEFRONT TRAIL   \n",
      "4    5     55302     51455    -7%  JACKSON PARK LAGOON SOUTH CORNELL DRIVE   \n",
      "\n",
      "     zip  \n",
      "0  60647  \n",
      "1  60622  \n",
      "2  60653  \n",
      "3  60653  \n",
      "4  60637  \n"
     ]
    }
   ],
   "source": [
    "land_use = pd.read_pickle('land_use.p')\n",
    "print(land_use.head())\n",
    "print(census.head())\n",
    "#print(licenses.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ward  pop_2010  vacant  account\n",
      "47    7     51581      19       80\n",
      "12   20     52372      15      123\n",
      "1    10     51535      14      130\n",
      "16   24     54909      13       98\n",
      "7    16     51954      13      156\n"
     ]
    }
   ],
   "source": [
    "# Merge land_use and census and merge result with licenses including suffixes\n",
    "land_cen_lic = land_use.merge(census, on=\"ward\") \\\n",
    "    .merge(licenses, on='ward', suffixes = (\"_cen\", \"_lic\"))\n",
    "\n",
    "pop_vac_lic = land_cen_lic.groupby([\"ward\", \"pop_2010\", \"vacant\"],as_index=False).agg({\"account\" : \"count\"})\n",
    "#print(pop_vac_lic)\n",
    "\n",
    "sorted_pop_vac_lic = pop_vac_lic.sort_values([\"vacant\",\"account\",\"pop_2010\"], ascending=[False, True, True])\n",
    "\n",
    "# Print the top few rows of sorted_pop_vac_lic\n",
    "print(sorted_pop_vac_lic.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting missing rows with left join\n",
    "The Movie Database is supported by volunteers going out into the world, collecting data, and entering it into the database. This includes financial data, such as movie budget and revenue. If you wanted to know which movies are still missing data, you could use a left join to identify them. Practice using a left join by merging the movies table and the financials table.\n",
    "\n",
    "The **movies** and **financials** tables have been loaded for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### Question\n",
    "- What column is likely the best column to merge the two tables on?<br>**Possible Answers**:\n",
    "  - [ ] *on='budget'*\n",
    "\n",
    "  - [ ] *on='popularity'*\n",
    "\n",
    "  - [x] *on='id'*\n",
    "\n",
    "- Merge the **movies** table, as the left table, with the **financials** table using a left join, and save the result to **movies_financials**.\n",
    "- Count the number of rows in **movies_financials** with a *null* value in the **budget** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_pickle('movies.p')\n",
    "financials = pd.read_pickle('financials.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1574\n"
     ]
    }
   ],
   "source": [
    "movies_financials = movies.merge(financials, on='id', how='left')\n",
    "\n",
    "# Count the number of rows in the budget column that are missing\n",
    "number_of_missing_fin = movies_financials['budget'].isnull().sum()\n",
    "\n",
    "# Print the number of movies missing financials\n",
    "print(number_of_missing_fin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enriching a dataset\n",
    "Setting **how='left'** with the **.merge()** method is a useful technique for enriching or enhancing a dataset with additional information from a different table. In this exercise, you will start off with a sample of movie data from the movie series *Toy Story*. Your goal is to enrich this data by adding the marketing tag line for each movie. You will compare the results of a left join versus an inner join.\n",
    "\n",
    "The **toy_story** DataFrame contains the Toy Story movies. The **toy_story** and **taglines** DataFrames have been loaded for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Merge **toy_story** and **taglines** on the **id** column with a left join, and save the result as toystory_tag.\n",
    "- With **toy_story** as the left table, merge to it **taglines** on the **id** column with an inner join, and save as **toystory_tag**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_story_dict = {\"id\" : [10193,863,862], \"title\": [\"Toy Story 3\",\"Toy Story 2\",\"Toy Story\"],\\\n",
    "    \"popularity\": [59.995418,73.575118,73.640445], \"release_date\":[\"2010-06-16\",\"1999-10-30\",\"1995-10-30\"]}\n",
    "toy_story = pd.DataFrame(toy_story_dict)\n",
    "taglines = pd.read_pickle('taglines.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id        title  popularity release_date                   tagline\n",
      "0  10193  Toy Story 3   59.995418   2010-06-16  No toy gets left behind.\n",
      "1    863  Toy Story 2   73.575118   1999-10-30        The toys are back!\n",
      "2    862    Toy Story   73.640445   1995-10-30                       NaN\n",
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "toystory_tag = toy_story.merge(taglines, on='id', how='left')\n",
    "# Print the rows and shape of toystory_tag\n",
    "print(toystory_tag)\n",
    "print(toystory_tag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id        title  popularity release_date                   tagline\n",
      "0  10193  Toy Story 3   59.995418   2010-06-16  No toy gets left behind.\n",
      "1    863  Toy Story 2   73.575118   1999-10-30        The toys are back!\n",
      "(2, 5)\n"
     ]
    }
   ],
   "source": [
    "# Merge the toy_story and taglines tables with a inner join\n",
    "toystory_tag = toy_story.merge(taglines, on='id', how='inner')\n",
    "\n",
    "# Print the rows and shape of toystory_tag\n",
    "print(toystory_tag)\n",
    "print(toystory_tag.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right join to find unique movies\n",
    "Most of the recent big-budget science fiction movies can also be classified as action movies. You are given a table of science fiction movies called **scifi_movies** and another table of action movies called **action_movies**. Your goal is to find which movies are considered only science fiction movies. Once you have this table, you can merge the **movies** table in to see the movie names. Since this exercise is related to science fiction movies, use a right join as your superhero power to solve this problem.\n",
    "\n",
    "The **movies, scifi_movies, and action_movies** tables have been loaded for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Merge **action_movies** and **scifi_movies** tables with a right join on **movie_id**. Save the result as **action_scifi**.\n",
    "\n",
    "- Update the merge to add suffixes, where *'_act'* and *'_sci'* are suffixes for the left and right tables, respectively.\n",
    "\n",
    "- From **action_scifi**, subset only the rows where the **genre_act** column is null.\n",
    "\n",
    "- Merge **movies** and **scifi_only** using the **id** column in the left table and the **movie_id** column in the right table with an inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_movies = pd.read_csv(\"action_movies.csv\")\n",
    "scifi_movies = pd.read_csv(\"scifi_movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                         title  popularity release_date  movie_id  \\\n",
      "0  18841  The Lost Skeleton of Cadavra    1.680525   2001-09-12     18841   \n",
      "1  26672     The Thief and the Cobbler    2.439184   1993-09-23     26672   \n",
      "2  15301      Twilight Zone: The Movie   12.902975   1983-06-24     15301   \n",
      "3   8452                   The 6th Day   18.447479   2000-11-17      8452   \n",
      "4   1649    Bill & Ted's Bogus Journey   11.349664   1991-07-19      1649   \n",
      "\n",
      "  genre_act        genre_sci  \n",
      "0       NaN  Science Fiction  \n",
      "1       NaN  Science Fiction  \n",
      "2       NaN  Science Fiction  \n",
      "3       NaN  Science Fiction  \n",
      "4       NaN  Science Fiction  \n",
      "(258, 7)\n"
     ]
    }
   ],
   "source": [
    "action_scifi = action_movies.merge(scifi_movies, on=\"movie_id\", how='right', suffixes=(\"_act\",\"_sci\"))\n",
    "\n",
    "scifi_only = action_scifi[action_scifi['genre_act'].isnull()]\n",
    "\n",
    "movies_and_scifi_only = movies.merge(scifi_only, left_on=\"id\", right_on=\"movie_id\", how=\"inner\")\n",
    "print(movies_and_scifi_only.head())\n",
    "print(movies_and_scifi_only.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popular genres with right join\n",
    "What are the genres of the most popular movies? To answer this question, you need to merge data from the **movies** and **movie_to_genres** tables. In a table called **pop_movies**, the top 10 most popular movies in the movies table have been selected. To ensure that you are analyzing all of the popular movies, merge it with the **movie_to_genres** table using a right join. To complete your analysis, count the number of different genres. Also, the two tables can be merged by the movie ID. However, in **pop_movies** that column is called **id**, and in **movies_to_genres** it's called **movie_id**.\n",
    "\n",
    "The **pop_movies** and **movie_to_genres** tables have been loaded for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Merge **movie_to_genres** and **pop_movies** using a right join. Save the results as **genres_movies**.\n",
    "- Group **genres_movies** by **genre** and **count** the number of **id** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_to_genres = pd.read_pickle('movie_to_genres.p')\n",
    "pop_movies = pd.read_csv('pop_movies.csv')\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "genres_movies = movie_to_genres.merge(pop_movies, left_on=\"movie_id\", right_on=\"id\", how=\"right\")\n",
    "\n",
    "genre_count = genres_movies.groupby(\"genre\").agg({'id':'count'})\n",
    "\n",
    "genre_count.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using outer join to select actors\n",
    "One cool aspect of using an outer join is that, because it returns all rows from both merged tables and null where they do not match, you can use it to find rows that do not have a match in the other table. To try for yourself, you have been given two tables with a list of actors from two popular movies: *Iron Man 1* and *Iron Man 2*. Most of the actors played in both movies. Use an outer join to find actors who **did not** act in both movies.\n",
    "\n",
    "The *Iron Man 1* table is called **iron_1_actors**, and Iron Man 2 table is called **iron_2_actors**. Both tables have been loaded for you and a few rows printed so you can see the structure.\n",
    "\n",
    "Venn graph with no overlap\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Save to **iron_1_and_2** the merge of **iron_1_actors** **(left)** with **iron_2_actors** tables with an *outer* join on the **id** column, and set suffixes to **('_1','_2')**.\n",
    "- Create an index that returns **True** if **name_1** or **name_2** are **null**, and **False** otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "iron_1_actors = pd.read_csv('iron_1_actors.csv',encoding='latin-1')\n",
    "iron_2_actors = pd.read_csv('iron_2_actors.csv',encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   character_1      id           name_1 character_2 name_2\n",
      "0                       Yinsen   17857       Shaun Toub         NaN    NaN\n",
      "2  Obadiah Stane / Iron Monger    1229     Jeff Bridges         NaN    NaN\n",
      "3                  War Machine   18288  Terrence Howard         NaN    NaN\n",
      "5                         Raza   57452      Faran Tahir         NaN    NaN\n",
      "8                   Abu Bakaar  173810    Sayed Badreya         NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "# Merge iron_1_actors to iron_2_actors on id with outer join using suffixes\n",
    "iron_1_and_2 = iron_1_actors.merge(iron_2_actors,\n",
    "                                     on='id',\n",
    "                                     how='outer',\n",
    "                                     suffixes=('_1','_2'))\n",
    "\n",
    "# Create an index that returns true if name_1 or name_2 are null\n",
    "m = ((iron_1_and_2['name_1'].isnull()) | (iron_1_and_2['name_2'].isnull()))\n",
    "\n",
    "\n",
    "# Print the first few rows of iron_1_and_2\n",
    "print(iron_1_and_2[m].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Self join\n",
    "Merging a table to itself can be useful when you want to compare values in a column to other values in the same column. In this exercise, you will practice this by creating a table that for each movie will list the movie director and a member of the crew on one row. You have been given a table called **crews**, which has columns **id**, **job**, and **name**. First, merge the table to itself using the movie ID. This merge will give you a larger table where for each movie, every job is matched against each other. Then select only those rows with a director in the left table, and avoid having a row where the director's job is listed in both the left and right tables. This filtering will remove job combinations that aren't with the director.\n",
    "\n",
    "The **crews** table has been loaded for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- To a variable called **crews_self_merged**, merge the crews table to itself on the **id** column using an **inner** join, setting the suffixes to **'_dir'** and **'_crew'** for the left and *right* tables respectively.\n",
    "- Create a Boolean index, named **boolean_filter**, that selects rows from the left table with the job of **'Director'** and avoids rows with the *job of* **'Director'** in the right table.\n",
    "- Use the **.head()** method to print the first few rows of **direct_crews**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "crews = pd.read_pickle('crews.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id department_dir   job_dir       name_dir department_crew  \\\n",
      "156  19995      Directing  Director  James Cameron         Editing   \n",
      "157  19995      Directing  Director  James Cameron           Sound   \n",
      "158  19995      Directing  Director  James Cameron      Production   \n",
      "160  19995      Directing  Director  James Cameron         Writing   \n",
      "161  19995      Directing  Director  James Cameron             Art   \n",
      "\n",
      "           job_crew          name_crew  \n",
      "156          Editor  Stephen E. Rivkin  \n",
      "157  Sound Designer  Christopher Boyes  \n",
      "158         Casting          Mali Finn  \n",
      "160          Writer      James Cameron  \n",
      "161    Set Designer    Richard F. Mays  \n"
     ]
    }
   ],
   "source": [
    "# Merge the crews table to itself\n",
    "crews_self_merged = crews.merge(crews, on='id', how='inner', suffixes=('_dir','_crew'))\n",
    "\n",
    "# Create a Boolean index to select the appropriate\n",
    "boolean_filter = ((crews_self_merged['job_dir'] == \"Director\") & \\\n",
    "     (crews_self_merged['job_crew'] != \"Director\"))\n",
    "direct_crews = crews_self_merged[boolean_filter]\n",
    "\n",
    "# Print the first few rows of direct_crews\n",
    "print(direct_crews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index merge for movie ratings\n",
    "To practice merging on indexes, you will merge movies and a table called ratings that holds info about movie ratings. Make sure your merge returns all of the rows from the movies table and not all the rows of ratings table need to be included in the result.\n",
    "\n",
    "The **movies** and **ratings** tables have been loaded for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Merge **movies** and **ratings** on the index and save to a variable called **movies_ratings**, ensuring that all of the rows from the **movies** table are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19995</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206647</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49026</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49529</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  vote_average  vote_count\n",
       "0   19995           7.2     11800.0\n",
       "1     285           6.9      4500.0\n",
       "2  206647           6.3      4466.0\n",
       "3   49026           7.6      9106.0\n",
       "4   49529           6.1      2124.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_pickle('ratings.p')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                 title  popularity release_date  vote_average  \\\n",
      "0    257          Oliver Twist   20.415572   2005-09-23           6.7   \n",
      "1  14290  Better Luck Tomorrow    3.877036   2002-01-12           6.5   \n",
      "2  38365             Grown Ups   38.864027   2010-06-24           6.0   \n",
      "3   9672              Infamous    3.680896   2006-11-16           6.4   \n",
      "4  12819       Alpha and Omega   12.300789   2010-09-17           5.3   \n",
      "\n",
      "   vote_count  \n",
      "0       274.0  \n",
      "1        27.0  \n",
      "2      1705.0  \n",
      "3        60.0  \n",
      "4       124.0  \n"
     ]
    }
   ],
   "source": [
    "# Merge to the movies table the ratings table on the index\n",
    "movies_ratings = movies.merge(ratings, on='id', how='left')\n",
    "\n",
    "# Print the first few rows of movies_ratings\n",
    "print(movies_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do sequels earn more?\n",
    "It is time to put together many of the aspects that you have learned in this chapter. In this exercise, you'll find out which movie sequels earned the most compared to the original movie. To answer this question, you will merge a modified version of the sequels and financials tables where their index is the movie ID. You will need to choose a merge type that will return all of the rows from the sequels table and not all the rows of financials table need to be included in the result. From there, you will join the resulting table to itself so that you can compare the revenue values of the original movie to the sequel. Next, you will calculate the difference between the two revenues and sort the resulting dataset.\n",
    "\n",
    "The **sequels** and **financials** tables have been provided.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- With the **sequels** table on the left, merge to it the **financials** table on index named **id**, ensuring that all the rows from the **sequels** are returned and some rows from the other table may not be returned, Save the results to **sequels_fin**.\n",
    "- Merge the **sequels_fin** table to itself with an **inner** join, where the *left and right* tables merge on **sequel** and **id** respectively with suffixes equal to (**'_org','_seq')**, saving to **orig_seq**.\n",
    "- Select the **title_org**, **title_seq**, and **diff** columns of **orig_seq** and save this as **titles_diff**.\n",
    "- Sort by **titles_diff** by **diff** in **descending** order and print the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequels = pd.read_pickle('sequels.p')\n",
    "financials = pd.read_pickle('financials.p')\n",
    "sequels['id'] = sequels['id'].astype('str')\n",
    "financials['id'] = financials['id'].astype('str')\n",
    "sequels['sequel'] = sequels['sequel'].astype('str')\n",
    "sequels = sequels.set_index('id')\n",
    "financials = financials.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               title_org        title_seq          diff\n",
      "id                                                     \n",
      "331    Jurassic Park III   Jurassic World  1.144748e+09\n",
      "272        Batman Begins  The Dark Knight  6.303398e+08\n",
      "10138         Iron Man 2       Iron Man 3  5.915067e+08\n",
      "863          Toy Story 2      Toy Story 3  5.696028e+08\n",
      "10764  Quantum of Solace          Skyfall  5.224703e+08\n"
     ]
    }
   ],
   "source": [
    "# Merge sequels and financials on index id\n",
    "sequels_fin = sequels.merge(financials, on='id', how='left')\n",
    "\n",
    "# Self merge with suffixes as inner join with left on sequel and right on id\n",
    "orig_seq = sequels_fin.merge(sequels_fin, how='inner', left_on='sequel',\\\n",
    "    right_on='id', right_index=True,suffixes=('_org','_seq'))\n",
    "\n",
    "orig_seq['diff'] = orig_seq['revenue_seq'] - orig_seq['revenue_org']\n",
    "\n",
    "# Select the title_org, title_seq, and diff \n",
    "titles_diff = orig_seq[[\"title_org\",'title_seq','diff']]\n",
    "\n",
    "print(titles_diff.sort_values('diff', ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_org</th>\n",
       "      <th>title_seq</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Toy Story 2</td>\n",
       "      <td>123812836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Toy Story 2</td>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>569602834.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince</td>\n",
       "      <td>-4253541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>192601579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>54919036.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Before Sunrise</td>\n",
       "      <td>Before Sunset</td>\n",
       "      <td>10457210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>Clerks</td>\n",
       "      <td>Clerks II</td>\n",
       "      <td>23737246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9367</th>\n",
       "      <td>El Mariachi</td>\n",
       "      <td>Desperado</td>\n",
       "      <td>23364525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>The Boondock Saints</td>\n",
       "      <td>The Boondock Saints II: All Saints Day</td>\n",
       "      <td>10598850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16186</th>\n",
       "      <td>Diary of a Mad Black Woman</td>\n",
       "      <td>Madea's Family Reunion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title_org  \\\n",
       "id                                                         \n",
       "862                                            Toy Story   \n",
       "863                                          Toy Story 2   \n",
       "675            Harry Potter and the Order of the Phoenix   \n",
       "121                The Lord of the Rings: The Two Towers   \n",
       "120    The Lord of the Rings: The Fellowship of the Ring   \n",
       "...                                                  ...   \n",
       "76                                        Before Sunrise   \n",
       "2292                                              Clerks   \n",
       "9367                                         El Mariachi   \n",
       "8374                                 The Boondock Saints   \n",
       "16186                         Diary of a Mad Black Woman   \n",
       "\n",
       "                                           title_seq         diff  \n",
       "id                                                                 \n",
       "862                                      Toy Story 2  123812836.0  \n",
       "863                                      Toy Story 3  569602834.0  \n",
       "675           Harry Potter and the Half-Blood Prince   -4253541.0  \n",
       "121    The Lord of the Rings: The Return of the King  192601579.0  \n",
       "120            The Lord of the Rings: The Two Towers   54919036.0  \n",
       "...                                              ...          ...  \n",
       "76                                     Before Sunset   10457210.0  \n",
       "2292                                       Clerks II   23737246.0  \n",
       "9367                                       Desperado   23364525.0  \n",
       "8374          The Boondock Saints II: All Saints Day   10598850.0  \n",
       "16186                         Madea's Family Reunion          NaN  \n",
       "\n",
       "[90 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing an anti-join\n",
    "In our music streaming company dataset, each customer is assigned an employee representative to assist them. In this exercise, filter the employee table by a table of top customers, returning only those employees who are not assigned to a customer. The results should resemble the results of an anti-join. The company's leadership will assign these employees additional training so that they can work with high valued customers.\n",
    "\n",
    "The **top_cust** and **employees** tables have been provided for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Merge **employees** and **top_cust** with a left join, setting **indicator** argument to **True**. Save the result to **empl_cust**.\n",
    "- Select the srid column of **empl_cust** and the rows where **_merge** is '**left_only**'. Save the result to **srid_list**.\n",
    "- Subset the employees table and select those rows where the srid is in the variable **srid_list** and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = pd.read_csv('employees.csv')\n",
    "top_cust = pd.read_csv('top_cust.csv', encoding='latin' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   srid     lname    fname            title   hire_date  \\\n",
      "0     1     Adams   Andrew  General Manager   8/14/2002   \n",
      "1     2   Edwards    Nancy    Sales Manager    5/1/2002   \n",
      "5     6  Mitchell  Michael       IT Manager  10/17/2003   \n",
      "6     7      King   Robert         IT Staff    1/2/2004   \n",
      "7     8  Callahan    Laura         IT Staff    3/4/2004   \n",
      "\n",
      "                     email  \n",
      "0   andrew@chinookcorp.com  \n",
      "1    nancy@chinookcorp.com  \n",
      "5  michael@chinookcorp.com  \n",
      "6   robert@chinookcorp.com  \n",
      "7    laura@chinookcorp.com  \n"
     ]
    }
   ],
   "source": [
    "empl_cust = employees.merge(top_cust, on='srid', how='left', indicator=True)\n",
    "\n",
    "srid_list = empl_cust.loc[empl_cust['_merge'] == \"left_only\" , 'srid']\n",
    "\n",
    "print(employees[employees['srid'].isin(srid_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing a semi-join\n",
    "Some of the tracks that have generated the most significant amount of revenue are from TV-shows or are other non-musical audio. You have been given a table of invoices that include top revenue-generating items. Additionally, you have a table of non-musical tracks from the streaming service. In this exercise, you'll use a semi-join to find the top revenue-generating non-musical tracks..\n",
    "\n",
    "The tables non_mus_tcks, top_invoices, and genres have been loaded for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Merge **non_mus_tcks** and **top_invoices** on **tid** using an inner join. Save the result as **tracks_invoices**.\n",
    "- Use **.isin()** to subset the rows of **non_mus_tck** where **tid** is in the **tid** column of **tracks_invoices**. Save the result as **top_tracks**.\n",
    "- Group **top_tracks** by **gid** and count the **tid** rows. Save the result to **cnt_by_gid**.\n",
    "- Merge **cnt_by_gid** with the **genres** table on **gid** and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c49298971bf539fe56860cf72510440f9c691c8b4f7aa806b89e675cbf902fa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
